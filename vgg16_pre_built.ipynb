{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/seyyidahmeddjellouli/Deep-Learning-CNN-Course/blob/main/vgg16_pre_built.ipynb",
      "authorship_tag": "ABX9TyOd5gwQL9NxrpXqSZFd4yS3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyyidahmeddjellouli/Deep-Learning-CNN-Course/blob/main/vgg16_pre_built.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using a pre-built CNN\n",
        "In this notebook we are going to use a CNN model that was trained on the ImageNet dataset. The dataset consists of 1.4 million images in 1,000 categories. There are a number of models trained on this dataset. We will use one calle VGG16, which was developed by Karen Simonyan and Andrew Zisserman in 2014."
      ],
      "metadata": {
        "id": "h07jA8NFiPa2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WtvE2uBQh7wm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68327908-7276-4825-e153-0be96f03e611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's import the VGG16 model:"
      ],
      "metadata": {
        "id": "18ockZmrigQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "vgg = VGG16(weights='imagenet',\n",
        "                  input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "EYSxBBovihGj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the structure of the model:"
      ],
      "metadata": {
        "id": "ZcvlzNwBivPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUhBz82NinfT",
        "outputId": "2e100209-7e24-4baf-87f3-4e040fd08d70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classify a photo\n",
        "\n"
      ],
      "metadata": {
        "id": "Jy8mSNQTkNtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "filename='filename.jpeg'\n",
        "image = load_img(filename, target_size=(224, 224))\n",
        "\n",
        "# now convert it to a numpy array\n",
        "image = img_to_array(image)\n",
        "\n",
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
      ],
      "metadata": {
        "id": "WYk5dao0ivFZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)"
      ],
      "metadata": {
        "id": "wHev6nA1jv1j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the probability across all output classes\n",
        "predictions = vgg.predict(image)"
      ],
      "metadata": {
        "id": "85gdfSCEl73m",
        "outputId": "6d498cac-e111-403b-ef54-0fe75b9f8d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import decode_predictions\n",
        "# convert the probabilities to class labels\n",
        "labels = decode_predictions(predictions, top=3)\n",
        "labels = labels[0]\n",
        "for label in labels:\n",
        "    print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "metadata": {
        "id": "AHi1r5x-l_wY",
        "outputId": "b8aef627-d434-4bfe-f5ab-b3ead12fc256",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "standard_poodle (92.18%)\n",
            "Irish_water_spaniel (5.34%)\n",
            "miniature_poodle (2.39%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dogPic = '687474703a2f2f7a6163686172736b692e6f72672f66696c65732f636f75727365732f63733337302f766767546573742f626f72646572436f6c6c69652e6a7067.jpeg'"
      ],
      "metadata": {
        "id": "uf3i5ZmBsV-Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.preprocessing.image import load_img\n",
        "#from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "image = load_img(dogPic, target_size=(224, 224))\n",
        "\n",
        "# now convert it to a numpy array\n",
        "image = img_to_array(image)\n",
        "\n",
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)"
      ],
      "metadata": {
        "id": "YFTpd9Bas45q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = load_img(dogPic, target_size=(224, 224))\n",
        "\n",
        "# now convert it to a numpy array\n",
        "image = img_to_array(image)\n",
        "\n",
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)\n",
        "\n",
        "# predict the probability across all output classes\n",
        "predictions = vgg.predict(image)\n",
        "\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "# convert the probabilities to class labels\n",
        "labels = decode_predictions(predictions, top=3)\n",
        "labels = labels[0]\n",
        "for label in labels:\n",
        "    print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "metadata": {
        "id": "9ggUIVYssjFC",
        "outputId": "b157f07a-d293-4e9a-f0b4-3d4b89a8f644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 670ms/step\n",
            "Border_collie (38.04%)\n",
            "Cardigan (15.88%)\n",
            "collie (10.69%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5J_CCtRzs0-Q"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}